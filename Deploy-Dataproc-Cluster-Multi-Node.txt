******************************************
******* CREATE MULTI-NODE CLUSTER ********
******************************************
gcloud dataproc clusters create bigspark33 \
  --project <PROJECT-ID> \
  --bucket <BUCKET-NAME> \
  --region us-east1 \
  --zone us-east1-b \
  --master-machine-type e2-highmem-4 \
  --master-boot-disk-size 50 \
  --num-workers 2 \
  --worker-machine-type e2-highmem-2 \
  --worker-boot-disk-size 50 \
  --optional-components=JUPYTER \
  --image-version 2.1-debian11 \
  --initialization-actions gs://dataproc-initialization-actions/python/pip-install.sh \
  --metadata 'PIP_PACKAGES=google-cloud-storage' \
  --enable-component-gateway

****************************************************
******* CREATE MULTI-NODE CLUSTER ONE-LINER ********
****************************************************
gcloud dataproc clusters create bigspark33 --project <PROJECT-ID> --bucket <BUCKET-NAME> --region us-east1 --zone us-east1-b --master-machine-type e2-highmem-4 --master-boot-disk-size 50 --num-workers 2 --worker-machine-type e2-highmem-2 --worker-boot-disk-size 50 --optional-components=JUPYTER --image-version 2.1-debian11 --initialization-actions gs://dataproc-initialization-actions/python/pip-install.sh --metadata 'PIP_PACKAGES=google-cloud-storage' --enable-component-gateway

**************************
******* SSH Tunnel *******
**************************
Select the cluster and under web interfaces select Jupyter or Jupyter Lab.
OR
gcloud compute ssh bigspark33-m --zone us-east1-b -- -L 8080:localhost:8123

********************************
******* JUPYTER NOTEBOOK *******
********************************
localhost:8080

*********************************
******* TERMINATE CLUSTER *******
*********************************
gcloud dataproc clusters delete bigspark33 --region us-east1
